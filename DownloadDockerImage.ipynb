{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DockerPull.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwy_VUNv5-dq"
      },
      "outputs": [],
      "source": [
        "script=r\"\"\"#!/usr/bin/python3\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import gzip\n",
        "from io import BytesIO\n",
        "import json\n",
        "import hashlib\n",
        "import shutil\n",
        "import requests\n",
        "import tarfile\n",
        "import urllib3\n",
        "urllib3.disable_warnings()\n",
        "\n",
        "if len(sys.argv) != 2 :\n",
        "\tprint('Usage:\\n\\tdocker_pull.py [registry/][repository/]image[:tag|@digest]\\n')\n",
        "\texit(1)\n",
        "\n",
        "# Look for the Docker image to download\n",
        "repo = 'library'\n",
        "tag = 'latest'\n",
        "imgparts = sys.argv[1].split('/')\n",
        "try:\n",
        "    img,tag = imgparts[-1].split('@')\n",
        "except ValueError:\n",
        "\ttry:\n",
        "\t    img,tag = imgparts[-1].split(':')\n",
        "\texcept ValueError:\n",
        "\t\timg = imgparts[-1]\n",
        "# Docker client doesn't seem to consider the first element as a potential registry unless there is a '.' or ':'\n",
        "if len(imgparts) > 1 and ('.' in imgparts[0] or ':' in imgparts[0]):\n",
        "\tregistry = imgparts[0]\n",
        "\trepo = '/'.join(imgparts[1:-1])\n",
        "else:\n",
        "\tregistry = 'registry-1.docker.io'\n",
        "\tif len(imgparts[:-1]) != 0:\n",
        "\t\trepo = '/'.join(imgparts[:-1])\n",
        "\telse:\n",
        "\t\trepo = 'library'\n",
        "repository = '{}/{}'.format(repo, img)\n",
        "\n",
        "# Get Docker authentication endpoint when it is required\n",
        "auth_url='https://auth.docker.io/token'\n",
        "reg_service='registry.docker.io'\n",
        "resp = requests.get('https://{}/v2/'.format(registry), verify=False)\n",
        "if resp.status_code == 401:\n",
        "\tauth_url = resp.headers['WWW-Authenticate'].split('\"')[1]\n",
        "\ttry:\n",
        "\t\treg_service = resp.headers['WWW-Authenticate'].split('\"')[3]\n",
        "\texcept IndexError:\n",
        "\t\treg_service = \"\"\n",
        "\n",
        "# Get Docker token (this function is useless for unauthenticated registries like Microsoft)\n",
        "def get_auth_head(type):\n",
        "\tresp = requests.get('{}?service={}&scope=repository:{}:pull'.format(auth_url, reg_service, repository), verify=False)\n",
        "\taccess_token = resp.json()['token']\n",
        "\tauth_head = {'Authorization':'Bearer '+ access_token, 'Accept': type}\n",
        "\treturn auth_head\n",
        "\n",
        "# Docker style progress bar\n",
        "def progress_bar(ublob, nb_traits):\n",
        "\tsys.stdout.write('\\r' + ublob[7:19] + ': Downloading [')\n",
        "\tfor i in range(0, nb_traits):\n",
        "\t\tif i == nb_traits - 1:\n",
        "\t\t\tsys.stdout.write('>')\n",
        "\t\telse:\n",
        "\t\t\tsys.stdout.write('=')\n",
        "\tfor i in range(0, 49 - nb_traits):\n",
        "\t\tsys.stdout.write(' ')\n",
        "\tsys.stdout.write(']')\n",
        "\tsys.stdout.flush()\n",
        "\n",
        "# Fetch manifest v2 and get image layer digests\n",
        "auth_head = get_auth_head('application/vnd.docker.distribution.manifest.v2+json')\n",
        "resp = requests.get('https://{}/v2/{}/manifests/{}'.format(registry, repository, tag), headers=auth_head, verify=False)\n",
        "if (resp.status_code != 200):\n",
        "\tprint('[-] Cannot fetch manifest for {} [HTTP {}]'.format(repository, resp.status_code))\n",
        "\tprint(resp.content)\n",
        "\tauth_head = get_auth_head('application/vnd.docker.distribution.manifest.list.v2+json')\n",
        "\tresp = requests.get('https://{}/v2/{}/manifests/{}'.format(registry, repository, tag), headers=auth_head, verify=False)\n",
        "\tif (resp.status_code == 200):\n",
        "\t\tprint('[+] Manifests found for this tag (use the @digest format to pull the corresponding image):')\n",
        "\t\tmanifests = resp.json()['manifests']\n",
        "\t\tfor manifest in manifests:\n",
        "\t\t\tfor key, value in manifest[\"platform\"].items():\n",
        "\t\t\t\tsys.stdout.write('{}: {}, '.format(key, value))\n",
        "\t\t\tprint('digest: {}'.format(manifest[\"digest\"]))\n",
        "\texit(1)\n",
        "layers = resp.json()['layers']\n",
        "\n",
        "# Create tmp folder that will hold the image\n",
        "imgdir = 'tmp_{}_{}'.format(img, tag.replace(':', '@'))\n",
        "os.mkdir(imgdir)\n",
        "print('Creating image structure in: ' + imgdir)\n",
        "\n",
        "config = resp.json()['config']['digest']\n",
        "confresp = requests.get('https://{}/v2/{}/blobs/{}'.format(registry, repository, config), headers=auth_head, verify=False)\n",
        "file = open('{}/{}.json'.format(imgdir, config[7:]), 'wb')\n",
        "file.write(confresp.content)\n",
        "file.close()\n",
        "\n",
        "content = [{\n",
        "\t'Config': config[7:] + '.json',\n",
        "\t'RepoTags': [ ],\n",
        "\t'Layers': [ ]\n",
        "\t}]\n",
        "if len(imgparts[:-1]) != 0:\n",
        "\tcontent[0]['RepoTags'].append('/'.join(imgparts[:-1]) + '/' + img + ':' + tag)\n",
        "else:\n",
        "\tcontent[0]['RepoTags'].append(img + ':' + tag)\n",
        "\n",
        "empty_json = '{\"created\":\"1970-01-01T00:00:00Z\",\"container_config\":{\"Hostname\":\"\",\"Domainname\":\"\",\"User\":\"\",\"AttachStdin\":false, \\\n",
        "\t\"AttachStdout\":false,\"AttachStderr\":false,\"Tty\":false,\"OpenStdin\":false, \"StdinOnce\":false,\"Env\":null,\"Cmd\":null,\"Image\":\"\", \\\n",
        "\t\"Volumes\":null,\"WorkingDir\":\"\",\"Entrypoint\":null,\"OnBuild\":null,\"Labels\":null}}'\n",
        "\n",
        "# Build layer folders\n",
        "parentid=''\n",
        "for layer in layers:\n",
        "\tublob = layer['digest']\n",
        "\t# FIXME: Creating fake layer ID. Don't know how Docker generates it\n",
        "\tfake_layerid = hashlib.sha256((parentid+'\\n'+ublob+'\\n').encode('utf-8')).hexdigest()\n",
        "\tlayerdir = imgdir + '/' + fake_layerid\n",
        "\tos.mkdir(layerdir)\n",
        "\n",
        "\t# Creating VERSION file\n",
        "\tfile = open(layerdir + '/VERSION', 'w')\n",
        "\tfile.write('1.0')\n",
        "\tfile.close()\n",
        "\n",
        "\t# Creating layer.tar file\n",
        "\tsys.stdout.write(ublob[7:19] + ': Downloading...')\n",
        "\tsys.stdout.flush()\n",
        "\tauth_head = get_auth_head('application/vnd.docker.distribution.manifest.v2+json') # refreshing token to avoid its expiration\n",
        "\tbresp = requests.get('https://{}/v2/{}/blobs/{}'.format(registry, repository, ublob), headers=auth_head, stream=True, verify=False)\n",
        "\tif (bresp.status_code != 200): # When the layer is located at a custom URL\n",
        "\t\tbresp = requests.get(layer['urls'][0], headers=auth_head, stream=True, verify=False)\n",
        "\t\tif (bresp.status_code != 200):\n",
        "\t\t\tprint('\\rERROR: Cannot download layer {} [HTTP {}]'.format(ublob[7:19], bresp.status_code, bresp.headers['Content-Length']))\n",
        "\t\t\tprint(bresp.content)\n",
        "\t\t\texit(1)\n",
        "\t# Stream download and follow the progress\n",
        "\tbresp.raise_for_status()\n",
        "\tunit = int(bresp.headers['Content-Length']) / 50\n",
        "\tacc = 0\n",
        "\tnb_traits = 0\n",
        "\tprogress_bar(ublob, nb_traits)\n",
        "\twith open(layerdir + '/layer_gzip.tar', \"wb\") as file:\n",
        "\t\tfor chunk in bresp.iter_content(chunk_size=8192): \n",
        "\t\t\tif chunk:\n",
        "\t\t\t\tfile.write(chunk)\n",
        "\t\t\t\tacc = acc + 8192\n",
        "\t\t\t\tif acc > unit:\n",
        "\t\t\t\t\tnb_traits = nb_traits + 1\n",
        "\t\t\t\t\tprogress_bar(ublob, nb_traits)\n",
        "\t\t\t\t\tacc = 0\n",
        "\tsys.stdout.write(\"\\r{}: Extracting...{}\".format(ublob[7:19], \" \"*50)) # Ugly but works everywhere\n",
        "\tsys.stdout.flush()\n",
        "\twith open(layerdir + '/layer.tar', \"wb\") as file: # Decompress gzip response\n",
        "\t\tunzLayer = gzip.open(layerdir + '/layer_gzip.tar','rb')\n",
        "\t\tshutil.copyfileobj(unzLayer, file)\n",
        "\t\tunzLayer.close()\n",
        "\tos.remove(layerdir + '/layer_gzip.tar')\n",
        "\tprint(\"\\r{}: Pull complete [{}]\".format(ublob[7:19], bresp.headers['Content-Length']))\n",
        "\tcontent[0]['Layers'].append(fake_layerid + '/layer.tar')\n",
        "\t\n",
        "\t# Creating json file\n",
        "\tfile = open(layerdir + '/json', 'w')\n",
        "\t# last layer = config manifest - history - rootfs\n",
        "\tif layers[-1]['digest'] == layer['digest']:\n",
        "\t\t# FIXME: json.loads() automatically converts to unicode, thus decoding values whereas Docker doesn't\n",
        "\t\tjson_obj = json.loads(confresp.content)\n",
        "\t\tdel json_obj['history']\n",
        "\t\ttry:\n",
        "\t\t\tdel json_obj['rootfs']\n",
        "\t\texcept: # Because Microsoft loves case insensitiveness\n",
        "\t\t\tdel json_obj['rootfS']\n",
        "\telse: # other layers json are empty\n",
        "\t\tjson_obj = json.loads(empty_json)\n",
        "\tjson_obj['id'] = fake_layerid\n",
        "\tif parentid:\n",
        "\t\tjson_obj['parent'] = parentid\n",
        "\tparentid = json_obj['id']\n",
        "\tfile.write(json.dumps(json_obj))\n",
        "\tfile.close()\n",
        "\n",
        "file = open(imgdir + '/manifest.json', 'w')\n",
        "file.write(json.dumps(content))\n",
        "file.close()\n",
        "\n",
        "if len(imgparts[:-1]) != 0:\n",
        "\tcontent = { '/'.join(imgparts[:-1]) + '/' + img : { tag : fake_layerid } }\n",
        "else: # when pulling only an img (without repo and registry)\n",
        "\tcontent = { img : { tag : fake_layerid } }\n",
        "file = open(imgdir + '/repositories', 'w')\n",
        "file.write(json.dumps(content))\n",
        "file.close()\n",
        "\n",
        "# Create image tar and clean tmp folder\n",
        "docker_tar = repo.replace('/', '_') + '_' + img + '.tar'\n",
        "sys.stdout.write(\"Creating archive...\")\n",
        "sys.stdout.flush()\n",
        "tar = tarfile.open(docker_tar, \"w\")\n",
        "tar.add(imgdir, arcname=os.path.sep)\n",
        "tar.close()\n",
        "shutil.rmtree(imgdir)\n",
        "print('\\rDocker image pulled: ' + docker_tar)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%store script > docker_pull.py\n",
        "!chmod +x docker_pull.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNKfzov76T2E",
        "outputId": "d391da63-f496-44ec-c2ca-35e2e211e5fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing 'script' (str) to file 'docker_pull.py'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./docker_pull.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuwCIG-H7D5c",
        "outputId": "492b9fe6-826e-4198-d4dd-a13d94526884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usage:\n",
            "\tdocker_pull.py [registry/][repository/]image[:tag|@digest]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Specify Docker Image\n",
        "image = \"alpine\" #@param {type:\"string\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "cWBsjyZj7kO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./docker_pull.py $image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqvmlXWE75Lj",
        "outputId": "fc27e4f9-2d2d-4e90-b499-f2950fb207a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating image structure in: tmp_alpine_latest\n",
            "df9b9388f04a: Pull complete [2814559]\n",
            "Docker image pulled: library_alpine.tar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/library_alpine.tar')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "dAPS8hqj-0zm",
        "outputId": "d5836f9c-4d01-424f-b49b-1c714bd72cd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9be39fe2-b4df-4b8f-b903-9b9c978a58fa\", \"library_alpine.tar\", 5867520)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In the target machine:\n",
        "# docker load < library_alpine.tar"
      ],
      "metadata": {
        "id": "pyfd2Lx1FTZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "eZRM8wLUFeHr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
